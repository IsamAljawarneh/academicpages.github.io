@INPROCEEDINGS{8024633,
  author={I. M. {Aljawarneh} and P. {Bellavista} and A. {Corradi} and R. {Montanari} and L. {Foschini} and A. {Zanotti}},
  booktitle={2017 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={Efficient spark-based framework for big geospatial data query processing and analysis}, 
  year={2017},
  volume={},
  number={},
  pages={851-856},
  abstract={The exponential amount of geospatial data that has been accumulated in an accelerated pace has inevitably motivated the scientific community to examine novel parallel technologies for tuning the performance of spatial queries. Managing spatial data for an optimized query performance is particularly a challenging task. This is due to the growing complexity of geometric computations involved in querying spatial data, where traditional systems failed to beneficially expand. However, the use of large-scale and parallel-based computing infrastructures based on cost-effective commodity clusters and cloud computing environments introduces new management challenges to avoid bottlenecks such as overloading scarce computing resources, which may be caused by an unbalanced loading of parallel tasks. In this paper, we aim to fill those gaps by introducing a generic framework for optimizing the performance of big spatial data queries on top of Apache Spark. Our framework also supports advanced management functions including a unique self-adaptable load-balancing service to self-tune framework execution. Our experimental evaluation shows that our framework is scalable and efficient for querying massive amounts of real spatial datasets.},
  keywords={Big Data;computational complexity;data analysis;data mining;geophysics computing;optimisation;parallel processing;query processing;resource allocation;software performance evaluation;visual databases;self-tuned framework execution;self-adaptable load-balancing service;advanced management functions;Apache Spark;scarce computing resource overloading;unbalanced loading;cloud computing;cost-effective commodity clusters;parallel-based computing infrastructures;large-scale computing infrastructures;geometric computational complexity;optimized query performance;spatial data management;spatial queries;performance tuning;scientific community;big geospatial data analysis;big geospatial data query processing;Spark-based framework;Spatial databases;Geospatial analysis;Sparks;Big Data;Clustering algorithms;Time factors;Computers;querying spatial data;MapReduce;big data;spark},
  doi={10.1109/ISCC.2017.8024633},
  ISSN={},
  month={July},}
